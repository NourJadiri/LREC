\section{Limitations and Future Work}

%\subsection{Limitations}

Our study, while demonstrating the effectiveness of the Agora framework, is subject to several \textbf{limitations} that offer avenues for future work.

\textbf{Model and API Dependency:} Our zero-shot framework relies on proprietary LLMs (e.g., gpt-5-nano). This limits full reproducibility, as performance is tied to specific, closed-source model versions. Future work should explore the effectiveness of this ensemble approach with open-source models to ensure broader accessibility and control.

\textbf{Prompt Sensitivity:} The performance of any zero-shot system is highly sensitive to prompt engineering. While we standardized prompts across configurations, it is possible that the specific phrasing influenced the degree of stochasticity observed and the effectiveness of the voting mechanism.

\textbf{Computational Cost:} Deploying a multi-agent ensemble incurs a direct multiplication of inference cost and latency compared to a single-agent system. In our $N=3$ configuration, the cost is roughly triple that of the baseline. While the performance gains justified this trade-off in a competitive setting, a critical area for future research is exploring cost-reduction techniques, such as using smaller, distilled models for some agents or implementing more sophisticated routing where an ensemble is only triggered for high-uncertainty cases.

%\subsection{Future Work}

Several promising directions emerge from this work. First, exploring weighted majority voting or dynamic ensemble triggering for high-uncertainty cases could optimize the cost-performance trade-off. Second, applying Agora to other hierarchical classification domains beyond propaganda detection would validate its generalizability. Finally, extending the framework to fine-tuned models on task-specific data, while addressing the challenge of preserving cultural nuances in multilingual settings, represents an important avenue for further performance improvements.
