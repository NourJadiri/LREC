\section{Conclusion}

We addressed the challenge of stochasticity in Large Language Models applied to Hierarchical Multi-Label Classification by introducing Agora, a multi-agent ensemble framework that leverages consensus-based voting to transform unreliable single-agent classification into a robust decision process.

Our experiments on SemEval-2025 Task 10 revealed three key findings: (1) naive single-pass LLM baselines are outperformed by sophisticated architectures, (2) Actor-Critic self-refinement can introduce noise and degrade performance due to critic unreliability, and (3) Agora with 3-agent voting delivers substantial performance gains across all languages, achieving first-place rankings in Hindi and competitive top-tier performance overall.

These results validate our central claim: multi-agent ensembling through consensus is a practical and effective method for building robust zero-shot classification systems. As NLP increasingly relies on powerful but imperfect LLMs, frameworks prioritizing reliability through consensus will be essential for trustworthy and deployable solutions.
