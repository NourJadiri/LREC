\section{Related Work}

The core challenge in Multi-Label Classification (MLC) has historically been the effective modeling of inter-label dependencies. 
Early methods sought to adapt single-label algorithms to this task. 
Approaches ranged from Binary Relevance, which simplifies the problem by training an independent classifier for each label but ignores correlations, to Classifier Chains, which attempt to capture dependencies by feeding the predictions of one classifier as features to the next in a sequence \citep{zhang_binary_2018,Read2011}. While foundational, these methods were often superseded by deep learning models, particularly Transformers, which could learn complex label correlations implicitly from large datasets \citep{devlin_bert_2019}.

Building on these advances, research into Hierarchical Multi-Label Classification (HMLC) focused on creating architectures that explicitly leverage the label taxonomy. A dominant paradigm involved coupling a Transformer-based text encoder with a Graph Neural Network (GNN) that operates on the label graph, allowing the model to learn hierarchy-aware representations and enforce structural consistency \citep{zhou-etal-2020-hierarchy,xu-etal-2021-hierarchical}. 
But the advent of Large Language Models (LLMs) has fundamentally shifted the landscape, enabling powerful zero-shot HMLC capabilities that bypass the need for complex, task-specific architectures and extensive supervised training \citep{wang-etal-2023-text2topic}.

The recent SemEval-2025 Task 10 on narrative detection \citep{semeval2025task10} exemplifies this modern, LLM-driven approach. 
State-of-the-art systems effectively use techniques like retrieval-augmented generation and specialized prompting to classify texts within the task's two-level hierarchy \citep{singh-etal-2025-gatenlp,younus-qureshi-2025-nlptuducd}. 
Prior work has also introduced modular ``agentic'' frameworks that decompose the task into parallel binary decisions \citep{eljadiri-nurbakova-2025-team}. 
Yet, these pioneering systems share a fundamental vulnerability: their reliance on a single, non-deterministic generative pass, which exposes them to the inherent stochasticity of LLMs. 

While ensembling is a well-established technique for improving robustness in supervised models \citep{jurkiewicz-etal-2020-applicaai}, its systematic application to mitigate the unreliability of zero-shot LLMs in HMLC remains underexplored. 
This represents a critical research gap: the stochasticity of individual LLM calls stands in stark contrast to the deterministic requirements of hierarchical classification systems, yet few works have investigated consensus-driven approaches to address this mismatch. 
Our work directly addresses this gap, proposing a multi-agent ensemble framework to produce stable, consensus-driven classifications that can reliably handle the demanding constraints of HMLC.
