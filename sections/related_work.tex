\section{Related Work}

The application of Large Language Models (LLMs) to Hierarchical Multi-Label Classification (HMLC) has rapidly matured, moving beyond complex supervised architectures that explicitly encode label hierarchies with Graph Neural Networks \citep{zhou-etal-2020-hierarchy} towards more flexible zero-shot paradigms \citep{wang-etal-2023-text2topic}. The recent SemEval-2025 Task 10 on multilingual narrative detection serves as a clear benchmark for the current state-of-the-art. Top-performing systems demonstrate the viability of zero-shot LLM approaches, utilizing techniques such as specialized prompting strategies and retrieval-augmented generation to handle the two-level taxonomy \citep{singh-etal-2025-gatenlp,younus-qureshi-2025-nlptuducd}.

In our own prior work on this task, we introduced a modular ``agentic'' framework that decomposed the HMLC problem into a set of parallel binary decisions, with specialized LLM agents assigned to individual labels \citep{eljadiri-nurbakova-2025-team}. While this and other systems have proven effective, they predominantly rely on the output of a single LLM agent or a single generative pass for their final predictions. This exposes them to the inherent stochasticity of LLMs, where identical inputs can yield different classifications across runs, posing a significant challenge for reliability. The use of ensembles to improve robustness is a well-established technique in machine learning \citep{Read2021} and has been effective for fine-tuned Transformer models in similar propaganda detection tasks \citep{jurkiewicz-etal-2020-applicaai}. However, the systematic application of ensembling to mitigate the unreliability of modern, zero-shot LLM systems in a complex HMLC context remains underexplored. Our work directly addresses this gap, proposing a multi-agent ensemble framework that aggregates votes to produce a more stable, consensus-driven classification.
