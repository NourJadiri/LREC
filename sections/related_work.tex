\section{Related Work}

\subsection{Traditional Multi-Label Classification Approaches}

The core challenge in Multi-Label Classification (MLC) has historically been the effective modeling of inter-label dependencies. Early problem-transformation methods sought to adapt single-label algorithms to this task. Approaches ranged from Binary Relevance, which simplifies the problem by training an independent classifier for each label but ignores correlations, to Classifier Chains, which attempt to capture dependencies by feeding the predictions of one classifier as features to the next in a sequence \citep{zhang_binary_2018,Read2011}. While foundational, these methods were often superseded by deep learning models, particularly Transformers, which could learn complex label correlations implicitly from large datasets \citep{devlin_bert_2019}.

\subsection{Hierarchical Multi-Label Classification}

For the more specific task of Hierarchical Multi-Label Classification (HMLC), research focused on creating architectures that explicitly leverage the label taxonomy. A dominant paradigm involved coupling a Transformer-based text encoder with a Graph Neural Network (GNN) that operates on the label graph, allowing the model to learn hierarchy-aware representations and enforce structural consistency \citep{zhou-etal-2020-hierarchy,xu-etal-2021-hierarchical}. However, the advent of Large Language Models (LLMs) has again shifted the landscape, enabling powerful zero-shot HMLC capabilities that bypass the need for complex, task-specific architectures and extensive supervised training \citep{wang-etal-2023-text2topic}.

\subsection{Zero-Shot LLM Approaches and Current Challenges}

The recent SemEval-2025 Task 10 on narrative detection serves as a clear benchmark for this modern, LLM-driven approach. State-of-the-art systems effectively use techniques like retrieval-augmented generation and specialized prompting to classify texts within the task's two-level hierarchy \citep{singh-etal-2025-gatenlp,younus-qureshi-2025-nlptuducd}. In our own prior work, we introduced a modular ``agentic'' framework that decomposed the task into parallel binary decisions \citep{eljadiri-nurbakova-2025-team}. Yet, these pioneering systems share a common vulnerability: their reliance on a single, non-deterministic generative pass, which exposes them to the inherent stochasticity of LLMs. While ensembling is a classic technique for improving robustness in supervised models \citep{jurkiewicz-etal-2020-applicaai}, its systematic application to mitigate the unreliability of zero-shot LLMs in HMLC remains underexplored. Our work directly addresses this gap, proposing a multi-agent ensemble framework to produce stable, consensus-driven classifications.
